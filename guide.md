arXiv:2410.17910v1 [cs.CR] 23 Oct 2024
# SLOT: Provenance-Driven APT Detection through Graph Reinforcement Learning
Wei Qiao

Xidian University

State Key Laboratory of Integrated

Services Networks (ISN)

Xi'an, China

qiaowei@iie.ac.cn
Zijian Zhang

Beijing Institute of Technology

Beijing, China

zhangzijian@bit.edu.cn
Yulong Shen

Xidian University

Xi'an, China

ylshen@mail.xidian.edu.cn

Yebo Feng

Nanyang Technological University

Singapore

yebo.feng@ntu.edu.sg
Zhengzi Xu

Imperial Global Singapore

Singapore

z.xu@imperial.ac.uk
JianFeng Ma

Xidian University

Xi'an, China

jfma@mail.xidian.edu.cn

Teng Li*

Xidian University

State Key Laboratory of Integrated

Services Networks (ISN)

Xi'an, China

tengli@xidian.edu.cn
Zhuo Ma

Xidian University

Xi'an, China

mazhuo@mail.xidian.edu.cn
Yang Liu

Nanyang Technological University

Singapore

yangliu@ntu.edu.sg
## Abstract
Advanced Persistent Threats (APTs) represent sophisticated cyberattacks characterized by their ability to remain undetected within the victim system for extended periods, aiming to exfiltrate sensitive data or disrupt operations. Existing detection approaches often struggle to effectively identify these complex threats, construct the attack chain for defense facilitation, or resist adversarial attacks. To overcome these challenges, we propose SLOT, an advanced APT detection approach based on provenance graphs and graph reinforcement learning. SLOT excels in uncovering multi-level hidden relationships, such as causal, contextual, and indirect connections, among system behaviors through provenance graph mining. By pioneering the integration of graph reinforcement learning, SLOT dynamically adapts to new user activities and evolving attack strategies, enhancing its resilience against adversarial attacks. Additionally, SLOT automatically constructs the attack chain according to detected attacks with clustering algorithms, providing precise identification of attack paths and facilitating the development of defense strategies. Evaluations with real-world datasets demonstrate SLOT's outstanding accuracy, efficiency, adaptability, and robustness in APT detection, with most metrics surpassing state-of-the-art methods. Additionally, case studies conducted to assess SLOT's effectiveness in supporting APT defense further establish it as a practical and reliable tool for cybersecurity protection.
CCS Concepts • Security and privacy → Intrusion detection systems.

Keywords APT, Graph Neural Networks, Reinforcement Learning, Provenance Graph, Intrusion Detection System
## 1 Introduction
An Advanced Persistent Threat (APT) is a sophisticated cyberattack in which a malicious actor gains unauthorized access to a network, remaining undetected for a long time to steal sensitive data or disrupt system operations  $ [39] $ . These attacks are highly targeted, using advanced techniques to maintain stealth and persistence within the victim's network  $ [5] $ , resulting in severe damage to the victim's system. For example, the latest SektorCERT report from Denmark  $ [38] $  reveals that Sandworm, an APT hacking group, launched coordinated attacks on 22 Danish energy companies, causing widespread disconnection of remote devices. Additionally, Symantec researchers have uncovered a four-month APT operation by Grayling  $ [41] $ , targeting manufacturing, IT, and biomedical sectors in Taiwan, the US, and Vietnam, involving theft of sensitive data.
To effectively combat APTs, it is crucial to detect them early with both timeliness and precision. Traditional detection methods may struggle with these complex and prolonged attacks, often resulting in either inadequate accuracy or excessive time to produce detection results. Recently, researchers have increasingly utilized provenance graphs to trace APT activities, progressively achieving practical efficacy and efficiency.
Based on their methodologies, existing provenance-graph-based approaches for APT detection can be classified into three categories: 1) Statistics-based approaches  $ [14, 25, 44] $  consider infrequent events as suspicious and use provenance graphs to model and identify these events. However, these
 $ ^{*} $ Corresponding author: Teng Li, tengli@xidian.edu.cn.
1
approaches focus solely on direct event connections, overlooking the deep semantics and hidden relationships within provenance graphs, which can result in a high rate of false positives and diminished reliability. 2) Specification-based approaches  $ [13, 15, 16, 28, 29] $  leverage expert knowledge to develop heuristic rules for APT detection. While this method effectively maintains a low false positive rate in cases it covers, creating these heuristic rules demands substantial prior expert knowledge, which must be distilled and refined by experts, making it a resource-intensive process. 3) Learning-based approaches  $ [4, 12, 20, 24, 34, 37, 45, 49] $  use various deep learning techniques to model APT attack patterns and system behaviors, subsequently utilizing these models for APT detection. These methods can achieve satisfactory detection performance, particularly with the integration of provenance graphs and graph neural network (GNN), which can uncover subtle connections between system events to enhance APT detection. However, they remain vulnerable to adversarial attacks, where attackers can easily mimic legitimate users to mislead the model into producing incorrect detection results.
To address the aforementioned gaps, we introduce SLOT, an advanced APT detection approach based on provenance graphs and graph reinforcement learning. Unlike existing methods, SLOT offers improved accuracy in detecting APTs by thoroughly digging multi-level hidden relationships—such as causal, contextual, and indirect connections—within system behaviors using provenance graphs. Additionally, by incorporating graph reinforcement learning, SLOT can autonomously learn and adapt to new user activities and attack strategies without relying on threat reports derived from expert insights, thereby enhancing its adaptability and resilience against adversarial attacks. Furthermore, SLOT can automatically construct the attack chain, accurately identifying the attack path, which simplifies the defense process.
Slot is comprised of five integrated modules that work together to detect highly stealthy APT attacks and assist administrators in formulating effective defense strategies. (1) It begins with the Graph Construction Module, which processes system logs to create an initial provenance graph that reflects system behaviors. (2) The Latent Behavior Mining Module then applies attention mechanisms and graph transformation techniques to discover hidden relationships within the graph, enhancing the depth and comprehensiveness of subsequent analysis. (3) The Embedding Module utilizes a graph reinforcement learning algorithm (i.e., Bernoulli multi-armed bandit [50]) to embed semantic and topological features of graph nodes as vectors, aggregates similar nodes, and produces updated feature vectors to filter out camouflaged entities, thereby improving accuracy and robustness. (4) The Threat Detection Model, which combines a multilayer perceptron (MLP) [36] and Isolation Forest (iForest) [9] to comprehensively identify APTs. (5) Finally, the Attack Chain Reconstruction module traces the attack pathway by clustering correlative nodes, aiding in the development of effective defense strategies.
We evaluated SLOT using three publicly available APT datasets from well-respected institutions and research communities. The evaluation results show that SLOT achieves an overall detection accuracy of approximately 99%, outperforming all existing state-of-the-art (SOTA) techniques. Furthermore, SLOT completes the detection process more quickly. Additionally, we tested SLOT against adversarial strategies proposed by Goyal et al.  $ [10] $ , which involve altering the neighborhood of nodes in the attack graph to resemble benign nodes. Leveraging its graph reinforcement learning mechanism, SLOT exhibits enhanced resistance compared to SOTA approaches. Ultimately, SLOT has proven its effectiveness in tracing attack pathways and aiding in the development of defense strategies in case studies.
In summary, this paper makes the following contributions.
- We introduce SLOT, an accurate APT detection method designed to withstand adversarial environments. It excels at identifying malicious activities within extensive audit logs and can also reconstruct the attack chain, thereby aiding in the formulation of effective defense strategies.
• We propose an advanced graph mining technique capable of efficiently uncovering multi-level hidden relationships—such as causal, contextual, and indirect connections—within the graph.
- For the first time, we integrate reinforcement learning into provenance graph analysis. By embedding semantic and topological features and leveraging the adaptive dynamics of reinforcement learning, S $ _l $ or effectively endures highly adversarial environments.
- We performed comprehensive evaluations using real-world datasets, and the results underscore Slor's effectiveness in detecting APTs, its resilience against adversarial attacks, and its capability to support the development of effective defense strategies.
<div style="text-align: center;">Table 1. Obstacles that limit the performance of APT detection approaches.</div>


<table border=1 style='margin: auto; width: max-content;'><tr><td style='text-align: center;'>Model</td><td style='text-align: center;'>Threat Report</td><td style='text-align: center;'>Semantic Encoding</td><td style='text-align: center;'>Attack Reconstruction</td><td style='text-align: center;'>Adversarial Attacks</td><td style='text-align: center;'>Granularity</td></tr><tr><td style='text-align: center;'>SLOT</td><td style='text-align: center;'>✗</td><td style='text-align: center;'>✓</td><td style='text-align: center;'>✓</td><td style='text-align: center;'>✓</td><td style='text-align: center;'>Node</td></tr><tr><td style='text-align: center;'>Nodoze[14]</td><td style='text-align: center;'>✗</td><td style='text-align: center;'>✗</td><td style='text-align: center;'>✗</td><td style='text-align: center;'>✗</td><td style='text-align: center;'>Node</td></tr><tr><td style='text-align: center;'>Poirot[28]</td><td style='text-align: center;'>✓</td><td style='text-align: center;'>✓</td><td style='text-align: center;'>✓</td><td style='text-align: center;'>✗</td><td style='text-align: center;'>Graph</td></tr><tr><td style='text-align: center;'>Unicorn[12]</td><td style='text-align: center;'>✗</td><td style='text-align: center;'>✓</td><td style='text-align: center;'>✗</td><td style='text-align: center;'>✗</td><td style='text-align: center;'>Graph</td></tr><tr><td style='text-align: center;'>ShadeWatcher[49]</td><td style='text-align: center;'>✗</td><td style='text-align: center;'>✓</td><td style='text-align: center;'>✗</td><td style='text-align: center;'>✗</td><td style='text-align: center;'>Edge</td></tr><tr><td style='text-align: center;'>FLASH[37]</td><td style='text-align: center;'>✗</td><td style='text-align: center;'>✓</td><td style='text-align: center;'>✓</td><td style='text-align: center;'>✗</td><td style='text-align: center;'>Node</td></tr><tr><td style='text-align: center;'>MAGIC[17]</td><td style='text-align: center;'>✗</td><td style='text-align: center;'>✗</td><td style='text-align: center;'>✗</td><td style='text-align: center;'>✓</td><td style='text-align: center;'>Node</td></tr><tr><td style='text-align: center;'>ThreaTrace[45]</td><td style='text-align: center;'>✗</td><td style='text-align: center;'>✗</td><td style='text-align: center;'>✗</td><td style='text-align: center;'>✓</td><td style='text-align: center;'>Node</td></tr></table>
2
## 2 Related Work and Its Limitations
This section categorizes and summarizes the related work on APT detection and graph reinforcement learning, and discusses their respective limitations.
### 2.1 APT Detection
To effectively detect sophisticated APTs, provenance graphs are used to model system events and trace attacks. Recent detection methods can be classified into three categories  $ [49] $ : statistics-based, specification-based, and learning-based methods. And it lists the existing limitations of current approaches in Table 1.
Statistics-based approaches: Statistical methods  $ [14, 25, 44] $  assume that attacks correlate with unusual system activities, quantifying suspiciousness based on interaction frequencies among system entities. However, rare events aren't always anomalies. For instance, in our scenario 1, Firefox loads the benign module Org.chromium.iyhyah for the first time, which a statistical method flags as a false positive. This example shows that such methods fail to capture deep semantics and latent relationships, leading to high false positive rates.
Specification-based approaches: Specification-based methods match audit logs with threat report  $ [13, 28] $  or use expert knowledge for abnormality scoring  $ [16, 29] $ , raising alerts when anomalies exceed a set threshold. While expert-driven detection generally achieves a low false positive rate, it requires specialized expertise to design effective strategies. As systems evolve and attack techniques grow more sophisticated, continuous expert intervention is needed, making it difficult for the system to adapt dynamically to changes in the network environment.
Learning-based approaches: Learning-based methods have proven effective for classification and anomaly detection by modeling system behaviors from logs. For example, Unicorn  $ [12] $  uses graph similarity matching to identify anomalous graphs, but a single alert can involve thousands of logs, complicating verification. At the edge level, ShadeWatcher  $ [49] $  models system interactions using GNNs, but high computational costs arise from numerous edges. At the node level, FLASH  $ [37] $  and ThreaTrace  $ [45] $  utilize GNN to detect anomalies at the node level by learning the structural information of nodes and detecting deviations from this learned behavior. MAGIC  $ [17] $  utilizes masked autoencoder and KNN to identify abnormal nodes. While node-level detection effectively identifies anomalies, current methods fail to utilize heterogeneous entity information and overlook the impact of benign masquerading by neighboring nodes on embeddings. As exemplified in our attack scenario (Figure 1), embedding benign DNS resolution behaviors within the malicious red attack chain can disrupt the embedding representation of the root malicious node, "Firefox1", thereby enabling adversarial mimicry and evasion.
### 2.2 Graph Reinforcement Learning
Reinforcement Learning (RL) has recently achieved success in addressing challenges across various fields, including robotics  $ [21] $ , gaming  $ [7] $ , and natural language processing (NLP)  $ [42] $ . Researchers have found that RL methods enable effective exploration of the topological structures and attribute information of graphs by analyzing key components such as nodes, links, and subgraphs. SUGAR  $ [40] $  employs Q-learning to adaptively select significant subgraphs to represent discriminative information of the graphs. Bachu et al.  $ [6] $  develop perturbation strategies for local explanations of graph data by optimizing multi-objective scores. Other related works  $ [19, 48] $  have demonstrated impressive performances in graph representation learning through RL, proving its efficacy in this domain. But currently, graph reinforcement learning has not yet been attempted in the field of log-provenance detection.
## 3 Problem Formalization
In this section, we introduce real attack scenarios from the DARPA  $ [1] $  dataset to highlight the limitations of existing provenance-based APT detection systems. Additionally, we define the threat scenarios that the S $ \omega $ T must address and the objectives it aims to achieve.
### 3.1 Attack Scenario
Figure 1 illustrates a Firefox backdoor attack. The red subgraph represents a simplified version of the original attack. A victim computer running the vulnerable Firefox version 54.0.1 unknowingly interacts with a malicious ad server located at 146.153.68.151. This server exploits a backdoor in Firefox, injecting the binary executable 'Dragon' into the process memory. 'Dragon' subsequently spawns a new process with root privileges (/home/admin/profile), which connects to an attacker's server at 161.116.88.72, thus granting the attacker full access to the victim's computer.
The existing APT detection systems based on learning distinguish between attack activities (red entities) and benign behaviors (black entities) by analyzing behavior patterns in provenance graphs. Common DNS resolution behaviors (blue subgraph) can be classified more clearly as benign structures after repeated learning sessions. However, in APT attacks, attackers may familiarize themselves with and mimic common benign activities of the system over a long period of information infiltration, thereby launching adversarial attacks that embed these benign substructures into their attack tactics without altering the actual attack logic. By repeatedly performing these common benign activities, malicious processes can be misjudged as benign during the detection process, thus achieving attack evasion.
3
<div style="text-align: center;"><img src="https://pplines-online.bj.bcebos.com/deploy/official/paddleocr/pp-ocr-vl//16d757a5-1bbb-46f6-b3f2-e2dc3a53cf16/markdown_3/imgs/img_in_image_box_109_147_1115_470.jpg?authorization=bce-auth-v1%2F5cfe9a5e1454405eb2a975c43eace6ec%2F2025-11-04T09%3A16%3A45Z%2F-1%2F%2Fd1b0df51d1715361f58369d8b336ec878924473408895f318ca57f79831e883a" alt="Image" width="82%" /></div>

<div style="text-align: center;">Figure 1. An example of an attack provenance graph from the DARPA E3 dataset  $ [1] $ . Attackers launched a series of attacks exploiting the Firefox backdoor vulnerability, along with camouflage activities to cover up the attacks. S $ \omega $ r effectively identifies all critical attack components, as indicated by the red nodes in the figure.</div>

### 3.2 Threat Model
Building on prior APT detection research  $ [12, 37, 45, 49] $ , our study focuses on scenarios where attackers exploit software vulnerabilities and communication backdoors for system control and persistence. We exclude hardware trojans and side-channel attacks, which are undetectable through system audits. We assume attackers know the target hosts' benign activities, enabling mimicry attacks. Additionally, we consider audit log data secure, supported by robust security tracing  $ [32] $  and anti-tampering  $ [31] $ , making our provenance graphs reliable for effective threat detection and analysis.
### 3.3 Design Goals
To defend against APT attacks, SLOT models and analyzes system call data recorded by audit logs. The ultimate goal of SLOT is to provide security analysts with more effective and streamlined attack insights, thereby accelerating the alert handling process. We believe that APT detection should achieve the following objectives when raising alarms: (1) For the complex multi-stage characteristics of APT attacks, SLOT must have precise detection capabilities to identify attack-related entities; (2) Amid vast volumes of logs, SLOT should maintain a low false positive rate to prevent alert fatigue; (3) In the face of highly covert adversarial attacks, SLOT must be highly robust, capable of dealing with attackers' camouflaging behaviors; (4) Finally, SLOT should provide security analysts with more streamlined and effective traceable analysis results, enabling the validation of alarm events within a reasonable time cost.
## 4 Methodology
### 4.1 Overview
Slot is a fine-grained, adversarial threat provenance scheme. It leverages attention mechanisms and graph transformation techniques to uncover deep hidden relationships, and then combines reinforcement learning with the provenance graph to guide relational aggregation in GNN. Slot features flexible policy extension capabilities and dynamic adaptability, allowing it to address adversarial attacks in real-world scenarios. Slot not only provides malicious detection through model learning but also proposes a method for considering unknown anomalies. Finally, By integrating LPA and ATT&CK  $ [2] $  encoding, it offers a concise and low false-positive attack chain, effectively accelerating manual verification. Figure 2 depicts Slot's architecture consisting of five major components:
① Graph Construction ( $ §\ 4.2 $ ). Slot constructs a graph based on entity relationships from system call logs and extracts semantic information from the logs as initial provenance graph.
② Latent Behavior Mining ( $ § 4.3 $ ). Slot further explored the behavioral relationships on the original system provenance graph. It combined system call relationships to construct deeper path connections. This approach enriches event behaviors and accelerates the propagation of information within the graph.
③ Embedding with Graph Reinforcement Learning ( $ § $  4.4). In the graph embedding stage, SLOT captures system behavior patterns through graph reinforcement learning. Specifically, SLOT embeds the semantic features and the topological features of nodes as vectors to calculate the similarity between entities in the provenance graph. Subsequently, it uses a reinforcement learning strategy to guide the selection and aggregation of relationships in the GNN based on this similarity, thereby achieving effective modeling of system behavior and obtaining the true feature vectors of the nodes. ④ Threats Detection ( $ § $  4.5). Using the trained model, SLOT performs node representation on the test logs. For previously learned behavior patterns, SLOT can directly classify
4
<div style="text-align: center;"><img src="https://pplines-online.bj.bcebos.com/deploy/official/paddleocr/pp-ocr-vl//16d757a5-1bbb-46f6-b3f2-e2dc3a53cf16/markdown_4/imgs/img_in_image_box_109_142_1111_408.jpg?authorization=bce-auth-v1%2F5cfe9a5e1454405eb2a975c43eace6ec%2F2025-11-04T09%3A16%3A45Z%2F-1%2F%2Fd27e12b03815668b26149e34881c10942ccfbbf537ce8e07a26a395484852261" alt="Image" width="81%" /></div>

<div style="text-align: center;">Figure 2. The workflow of Slot.</div>

node vectors as benign or malicious. However, to address unknown behaviors in APT attacks, SLOT uses anomaly detection to identify entities that deviate from known behavior patterns. SLOT treats both malicious entities and anomalous entities as alert node.
⑤ Attack-chain Reconstruction ( $ §\ 4.6 $ ). To assist security analysts in alert verification, SLOT constructs scattered alert nodes into a complete attack activity chain, eliminating the need for tracing across thousands of nodes. SLOT classifies alert nodes into different attack chains by clustering, using the TTP (Tactics, Techniques, and Procedures) phase tags from the ATT&CK framework [2] along with the feature embeddings of the nodes.
### 4.2 Graph Construction
<div style="text-align: center;">Table 2. System behaviors extracted from audit logs.</div>


<table border=1 style='margin: auto; width: max-content;'><tr><td style='text-align: center;'>System Behavior</td><td style='text-align: center;'>Relation Description</td></tr><tr><td style='text-align: center;'>Process  $ \rightarrow $  R1  $ \rightarrow $  Process</td><td style='text-align: center;'>&quot;R1&quot;: &quot;fork&quot;, &quot;execute&quot;, &quot;exit&quot;, &quot;clone&quot;, etc.</td></tr><tr><td style='text-align: center;'>Process  $ \rightarrow $  R2  $ \rightarrow $  File</td><td style='text-align: center;'>&quot;R2&quot;: &quot;read&quot;, &quot;open&quot;, &quot;close&quot;, &quot;write&quot;, etc.</td></tr><tr><td style='text-align: center;'>Process  $ \rightarrow $  R3  $ \rightarrow $  Netflow</td><td style='text-align: center;'>&quot;R3&quot;: &quot;connect&quot;, &quot;send&quot;, &quot;recv&quot;, &quot;write&quot;, etc.</td></tr><tr><td style='text-align: center;'>Process  $ \rightarrow $  R4  $ \rightarrow $  Memory</td><td style='text-align: center;'>&quot;R4&quot;: &quot;read&quot;, &quot;mprotect&quot;, &quot;mmap&quot;, etc.</td></tr></table>
SOT constructs an initial system provenance graph using audit data collected from logging infrastructures such as Windows ETW, Linux Audit, and CamFlow  $ [33] $ . It adheres to the existing definitions of provenance graphs and employs recent graph preprocessing techniques  $ [37, 45] $ , abstracting events into subjects, objects, and relationships, as illustrated in Table 2. Here, source nodes like Process/Thread represent subjects, and target nodes like Files or sockets represent objects, with system call events serving as the relationships to form graph  $ \mathcal{G}(S, R, O) $ . In addition to focusing on system behaviors, SOT further enriches the relationships between behaviors and explores multi-hop latent relations in Section 4.3. Regarding node features, SOT fully considers meaningful semantic information such as process names and command-line parameters for process nodes, file paths for file nodes, network IP addresses and ports for netflow nodes. By employing the Word2Vec model  $ [27] $ , SOT learns vector representations of these semantics, effectively mining the semantic expressions in provenance logs.
### 4.3 Latent Behavior Mining
<div style="text-align: center;"><img src="https://pplines-online.bj.bcebos.com/deploy/official/paddleocr/pp-ocr-vl//16d757a5-1bbb-46f6-b3f2-e2dc3a53cf16/markdown_4/imgs/img_in_image_box_647_667_1104_869.jpg?authorization=bce-auth-v1%2F5cfe9a5e1454405eb2a975c43eace6ec%2F2025-11-04T09%3A16%3A45Z%2F-1%2F%2F29824e16a9d7546099fcbd3969ecf9e40e7da9b348c095968db56f8ff8ab157a" alt="Image" width="37%" /></div>

<div style="text-align: center;">Figure 3. Latent behavior adjacency matrix construction, with colored edges indicating different relationships.</div>

In the mining of latent relationships, SLOT leverages attention mechanisms [43] and graph transformation [47] techniques to automatically mine advanced behavioral paths. For basic system call behavior  $ r_{i} $ , it mines deep path-behavior relationships  $ p_{ik} \in P_{i} $ , and then integrates low-dimensional overall system relationships with path-based advanced behavioral relationships to generate a new provenance graph. We define  $ p_{ik} = r_{i1}, r_{i2}, \ldots, r_{iL} $ , represented as an L-hop event path, where each  $ r_{il} \in p_{ik} $  is a basic system call behavior in the event path. In the path generation module, we use multiple attention mechanisms to softly select L relationships and combine these relationships to form path  $ P_{ik} $ . Specifically, for sub-behaviors within events, we generate corresponding relationship embedding using attention mechanisms:  $ r_{il} = \sum_{j=1}^{n} \alpha_{ij}^{l} r_{j} $ , where  $ \alpha_{ij}^{l} $  is calculated through scores normalized by the softmax function, which is computed as follows:
 $$ \alpha_{i j}^{l}=\frac{\exp(\mathbf{r}_{j}^{T}\sigma(\mathbf{r}_{i}\mathbf{W}^{l}+\mathbf{b}^{l}))}{\sum_{j^{\prime}=1}^{n}\exp(\mathbf{r}_{j^{\prime}}^{T}\sigma(\mathbf{r}_{i}\mathbf{W}^{l}+\mathbf{b}^{l}))}, $$ 
(1)
5
where W and b are parameters used in the path generation process, and  $ \sigma $  represents the activation function. By incorporating attention mechanisms, the model can effectively select multi-hop paths most relevant to a given relationship  $ r_{i} $ , thereby enhancing the representation of complex relationships between entities in the provenance graph. For each path  $ p_{ik} $  composed of L hops, its adjacency matrix  $ A_{p_{ki}} $  is obtained by the product of the adjacency matrices of the corresponding relationships:  $ A_{p_{ik}} = A_{r_{i1}} \cdot A_{r_{i2}} \ldots A_{r_{iL}} $ , where each  $ A_{r_{il}} $  is the adjacency matrix for the relationship  $ r_{il} $ . Direct computation of this product can be resource-intensive, so our method uses an efficient representation to approximate this process. First, each relationship's adjacency matrix is approximated by  $ A_{ril} \approx E \cdot \text{diag}(r_{il}) \cdot E^{T} $ , where E represents the matrix of entity embeddings, and  $ \text{diag}(r_{il}) $  transforms the relationship embedding  $ r_{il} $  into a diagonal matrix form. As shown in Figure 3, the adjacency matrix for the path  $ A_{p_{ik}} $  can be calculated as follows to capture the composite effect of multiple relationships along the path:
 $$ \begin{aligned}A_{p_{ik}}&\approx(\mathbf{E}\cdot\mathrm{diag}(\mathbf{r}_{i1})\cdot\mathbf{E}^{T})\cdot\cdots\cdot(\mathbf{E}\cdot\mathrm{diag}(\mathbf{r}_{iL})\cdot\mathbf{E}^{T})\\&\approx\mathrm{diag}(\mathbf{r}_{i1})\cdot\mathbf{E}^{T}\cdots\mathbf{E}\cdot\mathrm{diag}(\mathbf{r}_{iL})\\&\approx\mathbf{E}\cdot\mathbf{p}_{ik}\cdot\mathbf{E}^{T}.\end{aligned} $$ 
(2)
4.4 Embedding with Graph Reinforcement Learning

 $ S_{lot} $  utilizes graph reinforcement learning to obtain high-quality node embeddings from the provenance graph. The embedding module consists of three stages: 1) In the similarity-aware phase, the node's semantic features and topological features are embedded into vectors. 2) Based on the similarity calculation of node feature vectors, we design an adaptive Bandit neighbor selector using reinforcement learning [35]. Finally, we aggregate features by integrating multiple relationships (including system call and latent relationships) to generate updated node feature vectors.
#### 4.4.1 Feature-Topology Similarity Awareness
<div style="text-align: center;"><img src="https://pplines-online.bj.bcebos.com/deploy/official/paddleocr/pp-ocr-vl//16d757a5-1bbb-46f6-b3f2-e2dc3a53cf16/markdown_5/imgs/img_in_image_box_110_1064_581_1220.jpg?authorization=bce-auth-v1%2F5cfe9a5e1454405eb2a975c43eace6ec%2F2025-11-04T09%3A16%3A46Z%2F-1%2F%2F103e3d5e720a3e4b06b0beb9a1d5bf0368dd2b8901c14685978f8ef538047e02" alt="Image" width="38%" /></div>

<div style="text-align: center;">Figure 4. Embed semantic features and topological features as vectors.</div>

Previous research has explored various types of attacker camouflages from both behavioral  $ [18, 30] $  and semantic  $ [46] $  perspectives. These camouflages can make the features of malicious activities similar to those of benign entities, further inducing GNN to generate incorrect node embeddings. To address these issues of node feature camouflage, we believe that an effective similarity metric is necessary to filter out disguised neighbors before applying GNNs. SLOT achieves lightweight node similarity awareness by simultaneously considering node attribute features and topological features  $ [22] $  shown in Figure 4.
MLP on node features. A simple approach to node classification is to ignore graph topology and simply train an MLP on node features. Research  $ [52] $  has demonstrated that MLPs can actually perform relatively well on heterogeneous graphs—achieving higher or roughly equivalent efficacy compared to various GNNs. Thus, we represent the node features as follows:
 $$ \mathbf{h}_{\mathbf{X}}=\operatorname{M L P}_{\mathbf{X}}(\mathbf{X})\in\mathbb{R}^{d\times n}, $$ 
(3)
where  $ R^{d \times n} $  denote the matrix of node features with input dimension d.
LINK regression on graph topology. Another extreme is LINK  $ [51] $ , a simple baseline that solely utilizes graph topology. We extend LINK to compute feature embeddings for the topological relationship A as follows:
 $$ \mathbf{h}_{\mathbf{A}}=M L P_{\mathrm{A}}(\mathbf{A})\in\mathbb{R}^{d\times n}. $$ 
(4)
Finally, we let  $ [h_{1}; h_{2}] $  denote concatenation of vectors  $ h_{1} $  and  $ h_{2} $  and map the entity feature vectors as:
 $$ \mathbf{h_{v}}=M L P_{f}\left(\sigma\left(\mathbf{W}[\mathbf{h_{A}};\mathbf{h_{X}}]+\mathbf{h_{A}}+\mathbf{h_{X}}\right)\right). $$ 
(5)
We use the L1 distance between the feature vectors of two nodes as their measure of similarity. For a center node v under relation r at the l-th layer and edge  $ (v, v^{\prime}) \in \mathcal{E}_{r}^{(l-1)} $ , we can define the similarity measure as:
 $$ \mathcal{D}^{(l)}(v,v^{\prime})=\left\|\sigma\left(M L P^{(l)}(\mathbf{h}_{v}^{(l-1)})\right)-\sigma\left(M L P^{(l)}(\mathbf{h}_{v^{\prime}}^{(l-1)})\right)\right\|_{1}. $$ 
(6)
#### 4.4.2 Adaptive Bandit Neighbor Selector
Given relation camouflage, attackers may connect to varying numbers of benign entities under different relationships  $ [10] $ . We should select similar neighbors (i.e., filter disguised neighbors) to enhance the capability of GNN. To adaptively select appropriate neighbors, we utilize a similarity-aware neighbor selector to filter out nodes exhibiting inappropriate behaviors due to adversarial actions or inaccurate feature extraction  $ [35] $ . More specifically, for each central node, the selector utilizes Top-p sampling and adaptive filtering thresholds to construct similar neighbors under each relationship.

Top-p Sampling.
Before aggregating information from the central node v and its neighbors, we perform Top-p sampling to filter dissimilar neighbors based on different relationships. The filtering threshold  $ p_{r}^{l} $  for the l-th layer relationship r is defined within the range  $ [0,1] $ , representing the selection ratio from all neighbors.

Finding the Optimal Thresholds with RL.
6
<div style="text-align: center;"><img src="https://pplines-online.bj.bcebos.com/deploy/official/paddleocr/pp-ocr-vl//16d757a5-1bbb-46f6-b3f2-e2dc3a53cf16/markdown_6/imgs/img_in_image_box_163_140_528_388.jpg?authorization=bce-auth-v1%2F5cfe9a5e1454405eb2a975c43eace6ec%2F2025-11-04T09%3A16%3A46Z%2F-1%2F%2F38b4f5409366fea8dfb9e6750c9f5e4979d58b8c720ee5f70cdf4bae4e6a96d2" alt="Image" width="29%" /></div>

<div style="text-align: center;">Figure 5. RL-guided graph neighbor node selection.</div>

The logic behind reinforced neighborhood selection is to mine appropriate neighbor nodes for the central node. Previous GNN-based Works  $ [37, 45] $  are built on homogeneous benchmark graphs, devoid of noise caused by disguised attackers. Inspired by neighborhood sampling  $ [35] $ , we found that the scenario of resisting neighborhood interference satisfies the conditions for applying a Bernoulli multi-armed bandit reinforcement learning approach, allowing for the adaptive selection of suitable neighborhoods for each central node. We represent the RL module as a Markov Decision Process MDP < A, S, R, T, F >, used for the filtering threshold of relationships. A is the action space, S is the node state, R is the reward function, T is the state transition, and F is the termination condition.
• Action The action in the RL model dictates the updates to  $ p_{r}^{(l)} $  according to the received rewards. Given that  $ p_{r}^{(l)} $  falls within the range [0, 1], we define the action  $ a_{r}^{(l)} $  as modifying  $ p_{r}^{(l)} $  by adding or subtracting a fixed increment  $ \tau \in [0, 1] $ .
- State Due to the inability to use the GNN’s loss as the environment state, we use the average node distance, computed through similarity-aware calculations, as the state. The average neighbor distance in train node  $ V_{train} $  at layer l under relation r during epoch e is:
 $$ \mathcal{S}(\mathcal{D}_{r}^{(l)})^{(e)}=\frac{\sum_{v\in\mathcal{V}_{t r a i n}}\mathcal{D}_{r}^{(l)}(v,v^{\prime})^{(e)}}{|\mathcal{V}_{t r a i n}|}. $$ 
(7)
• Reward The optimal  $ p(l)^{r} $  at layer l under relation r aims to find the most similar neighbors to the central node. We design a binary reward based on the difference in average distances between two consecutive epochs. We define the reward for epoch e as:
 $$ f(p_{r}^{(l)},a_{r}^{(l)})^{(e)}=\left\{\begin{array}{l}+1,\mathcal{S}(\mathcal{D}_{r}^{(l)})^{(e-1)}-\mathcal{S}(\mathcal{D}_{r}^{(l)})^{(e)}\geq0,\\ -1,\mathcal{S}(\mathcal{D}_{r}^{(l)})^{(e-1)}-\mathcal{S}(\mathcal{D}_{r}^{(l)})^{(e)}<0.\end{array}\right. $$ 
(8)
When the distance between two consecutive epochs is positive, the reward is positive; otherwise, the reward is negative. Finally, we greedily update the actions based on the rewards.

• Transition State transitions are achieved through the forward propagation of GNN. When the neighbor selection threshold changes, the embeddings of the nodes are updated, leading to an update of the entire system’s state.
• Terminal We define the terminal condition for RL as:
 $$ |\sum_{e-10}^{e}f(p_{r}^{(l)},a_{r}^{(l)})^{(e)}|\leq2,where\quad e\geq10. $$ 
(9)
It means that the RL converges in the recent ten epochs and indicates an optimal threshold  $  p_{r}^{(l)}  $  is discovered.
#### 4.4.3 Contextual Relationship Integrator
After filtering the neighbors for each relationship through reinforcement learning, we directly use the optimal filtering threshold  $ p_{r}^{(l)} $ , learned from the RL process as the aggregation weight between relationships. We then use a GNN to aggregate information from neighbors across different relationships, generating updated node feature vectors. Formally, at the l-th layer for relationship r, after applying top-p sampling, the neighbor aggregation for node v is defined as follows:
 $$ \mathbf{h}_{v,r}^{(l)}=\mathrm{ReLU}\left(\mathrm{GNN}_{r}^{(l)}\left(\left\{\mathbf{h}_{v^{\prime}}^{(l-1)}:(v,v^{\prime})\in\mathcal{E}_{r}^{(l)}\right\}\right)\right). $$ 
(10)
Then, we define the inter-relation aggregation as follows:
 $$ \mathbf{h}_{v}^{(l)}=\operatorname{ReLU}\left(\operatorname{GNN}_{all}^{(l)}\left(\mathbf{h}_{v}^{(l-1)}\oplus\left\{p_{r}^{(l)}\cdot\mathbf{h}_{v,r}^{(l)}\right\}\big|_{r=1}^{R}\right)\right) $$ 
(11)
### 4.5 Threats Detection
After obtaining the embeddings of the system entities, we perform threat detection using a trained MLP and anomaly-based Isolation Forest, classifying the system entities into benign, malicious, and anomalous categories.
Learning Detection. To classify the embedded features, we trained a MLP classifier. For jointly training the similarity measure with GNNs, a heuristic approach involves appending it as a new layer before the GCN aggregation layer. We define the cross-entropy loss for the MLP at the first layer as follows:
 $$ \mathcal{L}_{\mathrm{S i m i}}^{(1)}=\sum_{v\in\mathcal{V}}-\log\left(y_{v}\cdot\sigma\left(M L P^{(l)}(\mathbf{h}_{v}^{(l)})\right)\right). $$ 
(12)
For each node v, its final embedding is the output of the GNN at the last layer  $ \mathbf{z}_{v} = \mathbf{h}_{v}^{(L)} $ . We can define the loss of GNN as a cross-entropy loss function:
 $$ \mathcal{L}_{\mathrm{G N N}}=\sum_{v\in\mathcal{V}}-\log\left(y_{v}\cdot\sigma(M L P(\mathbf{z}_{v}))\right). $$ 
(13)
By combining the losses of the similarity modeling and the GNN modeling, we minimize the following objective function to learn parameters in our threats detection model:
 $$ \mathcal{L}=\mathcal{L}_{\mathrm{G N N}}+\lambda_{1}\mathcal{L}_{\mathrm{S i m i}}^{(1)}+\lambda_{2}||\Theta||_{2}, $$ 
(14)
where  $ \left\|\Theta\right\|_{2} $  is the L2-norm of all model parameters,  $ \lambda_{1} $  and  $ \lambda_{2} $  are weighting parameters. Finally, we can classify the node feature vectors using the trained MLP.
7
Anomaly Detection. Learning-based scheme is effective in detecting known benign or malicious patterns but struggles with identifying unknown anomalies. To address this limitation, we have additionally introduced an unsupervised detector on top of the supervised learning classifier to identify unknown anomalies, or outliers. The key intuition here is that anomalous entities, compared to learned behavior patterns, tend to be sparse and distant from other data points.
Slot utilizes an Isolation Forest [9] to partition node feature vectors and compute node anomaly scores. Initially, the feature vector h in the detection representation is normalized as  $ h' = \frac{h - \mu_{h}}{\sigma_{h}} $ . Subsequently, the node anomaly score is calculated as:
 $$ Score(\mathbf{h},n)=2^{-\frac{E(I(\mathbf{h}^{\prime}))}{c(n)}}, $$ 
(15)
where n represents the total number of samples, and  $ E(l(\mathbf{h}')) $  denotes the average path length of the data point across all trees, which indicates the average depth at which the data point is isolated (i.e., the path ends) in the tree.  $ c(n) $  represents the average path length of a data point in a completely random tree.
After parallel detection, SLOT combines the results of both classifiers to make the final decision. If the supervised learning model makes a high-confidence prediction about a behavior (either benign or malicious), that prediction is adopted. On the other hand, if the anomaly detection model indicates that the behavior might be anomalous, it is labeled as anomalous.
### 4.6 Attack-chain Reconstruction
Considering that node-based alerts are dispersed in extremely large provenance graphs, verifying an event activity requires a forward or backward traceability investigation of nodes. Dispersed nodes are inconvenient for security analysts to validate the analysis, and node-level based alerts are accompanied by a large number of false-positive nodes, which can lead to severe alert fatigue.
To address this challenge, we propose a novel reconstruction scheme based on alert nodes, which, unlike previous approaches  $ [8, 37] $  that directly employed clustering or path association, incorporates the ATT&CK framework  $ [2] $  into attack chain reconstruction for the first time. This method involves mapping attack techniques from the ATT&CK framework and assigning appropriate TTP (Tactics, Techniques, and Procedures) codes  $ t_{i} $  to each node. We represent TTPs using one-hot encoding; if the ATT&CK framework includes N distinct TTPs, each TTP is encoded as an N-dimensional vector, with the position corresponding to the TTP set to 1 and the rest set to 0, with each technique or tactic corresponding to one code. We concatenate the node features with the TTP codes to obtain the initial node label  $ x_{i} = [h_{i}; t_{i}] $ , and then update the node labels using the Label Propagation Algorithm (LPA):
 $$ \mathbf{y}_{i}^{(t+1)}=\mathrm{m o d e}(\mathbf{y}_{j}^{(t)}\in\mathcal{N}(i)). $$ 
(16)
where  $ y_{i} $  represents the label of node i during the i-th iteration,  $ N(i) $  denotes the set of neighboring nodes of i, and mode indicates the selection of the most frequent label. The label propagation process is repeated until the labels of all nodes no longer change. This combination of TTP patterns effectively filters out false positives within the attack chain and generates the final attack path.
## 5 Evaluation
In this section, experiments are performed to validate Slot's advantage and answer the following key research questions:
• RQ1: How effective is Slor in detecting APTs compared to current state-of-the-art approaches?
• RQ2: What is the system overhead associated with using Slot?
• RQ3: How effective are the components of our Slot in achieving their intended functions?
• RQ4: How do different hyperparameters influence the detection capabilities of Slot?
• RO5: How resilient is Slot to adversarial attacks?
• RQ6: How effectively does Slot facilitate the manual validation of alerts?
### 5.1 Experimental Setups
#### 5.1.1 Datasets
Evaluation of SIOT was conducted using three open-source datasets: StreamSpot [3], Unicorn Wget [12], and DARPA E3 [1]. StreamSpot and Unicorn both consist of batch audit logs simulated in controlled environments. The StreamSpot dataset includes 600 batch audit logs monitoring system calls under six unique scenarios. Five of these scenarios simulate benign user behaviors, while the attack scenario replicates a drive-by download attack. Unicorn comprises 150 batch logs collected using Camflow [33], with 125 logs representing benign activity and 25 containing supply chain attacks. These attacks are categorized as stealthy, designed to mimic benign system workflows, and are expected to be challenging to detect. The DARPA E3 dataset is part of the DARPA Transparent Computing program, collected during adversarial engagements within enterprise networks. The Red Team conducted APT attacks using various vulnerabilities to exfiltrate sensitive information, while the Blue Team aimed to identify these attacks by auditing network hosts and performing causal analysis.
#### 5.1.2 Baseline Methods
To compare the efficacy and efficiency of SLOT with state-of-the-art methods, we selected the following seven advanced APT detections at both the graph-level, node-level and edge-level granularity for evaluation. Specialized expert rules or
8
<div style="text-align: center;">Table 3. Overview of the experimental datasets.</div>


<table border=1 style='margin: auto; width: max-content;'><tr><td style='text-align: center;'>Dataset</td><td style='text-align: center;'>of Nodes</td><td style='text-align: center;'>of Edges (in millions)</td><td style='text-align: center;'>Attack batch/node</td><td style='text-align: center;'>Size (GB)</td></tr><tr><td style='text-align: center;'>StreamSpot</td><td style='text-align: center;'>999,999</td><td style='text-align: center;'>89.8</td><td style='text-align: center;'>100 batches</td><td style='text-align: center;'>2.8</td></tr><tr><td style='text-align: center;'>Unicorn Wget</td><td style='text-align: center;'>39,606,900</td><td style='text-align: center;'>145.9</td><td style='text-align: center;'>25 batches</td><td style='text-align: center;'>76.6</td></tr><tr><td style='text-align: center;'>DARPA E3-Trace</td><td style='text-align: center;'>3,288,676</td><td style='text-align: center;'>4</td><td style='text-align: center;'>68,082 nodes</td><td style='text-align: center;'>15</td></tr><tr><td style='text-align: center;'>DARPA E3-Cadets</td><td style='text-align: center;'>1,627,035</td><td style='text-align: center;'>2.8</td><td style='text-align: center;'>25,319 nodes</td><td style='text-align: center;'>18</td></tr><tr><td style='text-align: center;'>DARPA E3-Theia</td><td style='text-align: center;'>1,623,966</td><td style='text-align: center;'>3.3</td><td style='text-align: center;'>12,846 nodes</td><td style='text-align: center;'>18</td></tr></table>
threat reports for APT detection schemes are difficult to compare, so they are not taken into consideration.
## 1 ) graph-level detection
• StreamSpot [26]: It introduces a new similarity function for graphs, comparing them based on the relative frequency of local substructures represented as short strings.
• Unicorn [12]: UNICORN uses graph sketching to build an incrementally updatable, fixed size, longitudinal graph data structure 1 that enables efficient computation of graph statistics.
## 2 ) node-level detection
- Threatrace [45]: It uses GraphSAGE to execute node-level anomaly detection, learning the structural information of nodes and identifying anomalies based on deviations from this learned behavior.
• Log2vec [24]: It transforms the user’s log entries into heterogeneous graphs based on rules and expresses behavioral relationships through graph embedding.
• FLASH [37]: It uses word2vec for semantic learning and GraphSAGE [11] for graph structure to jointly represent log behavior for anomaly detection.
- MAGIC [17]: It learns system behavior through a masked autoencoder and then uses KNN to calculate node distances, identifying abnormal nodes.
3) egde-level detection
• ShadeWatcher [49]: It leverages TransR [23] and GNN to detect APTs based on recommendation.
#### 5.1.3 Implementation
We implement SOT using Pytorch, comprising approximately 3,000 lines of code. All models operate on Python 3.9, utilizing the Gensim library for the Word2Vec model. Regarding hyperparameters, we set all embedding dimensions to 64, and the learning rate to 0.01. We use Adam as the optimizer, with the similarity loss weight  $ (\lambda_{1}) $  set at 2 and the L2 regularization weight  $ (\lambda_{2}) $  set at 0.01. The RL action step size  $ (\tau) $  is configured to 0.02. In Section 5.5, we provide a detailed discussion on the impact of hyperparameter settings, offering a thorough analysis and explanation of the rationale behind the settings and the experimental logic. All experiments are performed on a server running Ubuntu 18.04 LTS with an Intel 13th Gen Core i7-1360P CPU (12 cores, 16 threads, base frequency 2.20 GHz), 32 GB RAM.
### 5.2 Overall Detection Efficacy Comparison (RQ1)
<div style="text-align: center;"><img src="https://pplines-online.bj.bcebos.com/deploy/official/paddleocr/pp-ocr-vl//16d757a5-1bbb-46f6-b3f2-e2dc3a53cf16/markdown_8/imgs/img_in_chart_box_638_265_1102_428.jpg?authorization=bce-auth-v1%2F5cfe9a5e1454405eb2a975c43eace6ec%2F2025-11-04T09%3A16%3A48Z%2F-1%2F%2F28247be4c3e97a1dc6168ed1aceae8d743be9ed6fece865c7e37d6d989af9e73" alt="Image" width="37%" /></div>

<div style="text-align: center;">Figure 6. Comparison of ROC Curves between SLoT and FLASH on the DARPA E3 Dataset.</div>

<div style="text-align: center;">Table 4. The comparison results between SLOt and state-of-the-art approaches.</div>


<table border=1 style='margin: auto; width: max-content;'><tr><td style='text-align: center;'>Datasets</td><td style='text-align: center;'>System</td><td style='text-align: center;'>Accuracy</td><td style='text-align: center;'>Precision</td><td style='text-align: center;'>Recall</td><td style='text-align: center;'>F1-Score</td><td style='text-align: center;'>FPR</td></tr><tr><td rowspan="4">StreamSpot</td><td style='text-align: center;'>StreamSpot</td><td style='text-align: center;'>66%</td><td style='text-align: center;'>73%</td><td style='text-align: center;'>91%</td><td style='text-align: center;'>81%</td><td style='text-align: center;'>6.6%</td></tr><tr><td style='text-align: center;'>Unicorn</td><td style='text-align: center;'>94%</td><td style='text-align: center;'>98%</td><td style='text-align: center;'>93%</td><td style='text-align: center;'>96%</td><td style='text-align: center;'>1.6%</td></tr><tr><td style='text-align: center;'>Threatrace</td><td style='text-align: center;'>96%</td><td style='text-align: center;'>95%</td><td style='text-align: center;'>93%</td><td style='text-align: center;'>96%</td><td style='text-align: center;'>0.4%</td></tr><tr><td style='text-align: center;'>S1OT</td><td style='text-align: center;'>99%</td><td style='text-align: center;'>99%</td><td style='text-align: center;'>99%</td><td style='text-align: center;'>99%</td><td style='text-align: center;'>0.1%</td></tr><tr><td style='text-align: center;'>Unicorn</td><td style='text-align: center;'>Unicorn</td><td style='text-align: center;'>90%</td><td style='text-align: center;'>86%</td><td style='text-align: center;'>95%</td><td style='text-align: center;'>90%</td><td style='text-align: center;'>15.5%</td></tr><tr><td rowspan="2">Wget</td><td style='text-align: center;'>Threatrace</td><td style='text-align: center;'>95%</td><td style='text-align: center;'>93%</td><td style='text-align: center;'>98%</td><td style='text-align: center;'>95%</td><td style='text-align: center;'>7.4%</td></tr><tr><td style='text-align: center;'>S1OT</td><td style='text-align: center;'>99%</td><td style='text-align: center;'>96%</td><td style='text-align: center;'>99%</td><td style='text-align: center;'>97%</td><td style='text-align: center;'>6%</td></tr><tr><td rowspan="2">DARPA E3</td><td style='text-align: center;'>Log2vec</td><td style='text-align: center;'>97%</td><td style='text-align: center;'>54%</td><td style='text-align: center;'>78%</td><td style='text-align: center;'>64%</td><td style='text-align: center;'>1.8%</td></tr><tr><td style='text-align: center;'>ThreaTrace</td><td style='text-align: center;'>98%</td><td style='text-align: center;'>72%</td><td style='text-align: center;'>99%</td><td style='text-align: center;'>83%</td><td style='text-align: center;'>1.1%</td></tr><tr><td rowspan="4">TRACE</td><td style='text-align: center;'>ShadeWatcher</td><td style='text-align: center;'>99%</td><td style='text-align: center;'>99%</td><td style='text-align: center;'>99%</td><td style='text-align: center;'>99%</td><td style='text-align: center;'>0.3%</td></tr><tr><td style='text-align: center;'>FLASH</td><td style='text-align: center;'>99%</td><td style='text-align: center;'>95%</td><td style='text-align: center;'>99%</td><td style='text-align: center;'>97%</td><td style='text-align: center;'>0.1%</td></tr><tr><td style='text-align: center;'>MAGIC</td><td style='text-align: center;'>99%</td><td style='text-align: center;'>99%</td><td style='text-align: center;'>99%</td><td style='text-align: center;'>99%</td><td style='text-align: center;'>0.1%</td></tr><tr><td style='text-align: center;'>S1OT</td><td style='text-align: center;'>100%</td><td style='text-align: center;'>96%</td><td style='text-align: center;'>99%</td><td style='text-align: center;'>97%</td><td style='text-align: center;'>0.1%</td></tr><tr><td style='text-align: center;'>DARPA E3</td><td style='text-align: center;'>Log2vec</td><td style='text-align: center;'>98%</td><td style='text-align: center;'>49%</td><td style='text-align: center;'>85%</td><td style='text-align: center;'>62%</td><td style='text-align: center;'>1.6%</td></tr><tr><td rowspan="4">CADETS</td><td style='text-align: center;'>ThreaTrace</td><td style='text-align: center;'>99%</td><td style='text-align: center;'>90%</td><td style='text-align: center;'>99%</td><td style='text-align: center;'>95%</td><td style='text-align: center;'>0.2%</td></tr><tr><td style='text-align: center;'>FLASH</td><td style='text-align: center;'>99%</td><td style='text-align: center;'>95%</td><td style='text-align: center;'>99%</td><td style='text-align: center;'>97%</td><td style='text-align: center;'>0.05%</td></tr><tr><td style='text-align: center;'>MAGIC</td><td style='text-align: center;'>99%</td><td style='text-align: center;'>94%</td><td style='text-align: center;'>99%</td><td style='text-align: center;'>97%</td><td style='text-align: center;'>0.2%</td></tr><tr><td style='text-align: center;'>S1OT</td><td style='text-align: center;'>99%</td><td style='text-align: center;'>96%</td><td style='text-align: center;'>99%</td><td style='text-align: center;'>97%</td><td style='text-align: center;'>0.1%</td></tr><tr><td style='text-align: center;'>DARPA E3</td><td style='text-align: center;'>Log2vec</td><td style='text-align: center;'>99%</td><td style='text-align: center;'>62%</td><td style='text-align: center;'>66%</td><td style='text-align: center;'>64%</td><td style='text-align: center;'>0.3%</td></tr><tr><td rowspan="4">THEIA</td><td style='text-align: center;'>ThreaTrace</td><td style='text-align: center;'>99%</td><td style='text-align: center;'>87%</td><td style='text-align: center;'>99%</td><td style='text-align: center;'>93%</td><td style='text-align: center;'>0.1%</td></tr><tr><td style='text-align: center;'>FLASH</td><td style='text-align: center;'>99%</td><td style='text-align: center;'>93%</td><td style='text-align: center;'>99%</td><td style='text-align: center;'>96%</td><td style='text-align: center;'>0.05%</td></tr><tr><td style='text-align: center;'>MAGIC</td><td style='text-align: center;'>99%</td><td style='text-align: center;'>98%</td><td style='text-align: center;'>99%</td><td style='text-align: center;'>99%</td><td style='text-align: center;'>0.1%</td></tr><tr><td style='text-align: center;'>S1OT</td><td style='text-align: center;'>99%</td><td style='text-align: center;'>95%</td><td style='text-align: center;'>99%</td><td style='text-align: center;'>97%</td><td style='text-align: center;'>0.03%</td></tr></table>
<div style="text-align: center;"> $ ^{1} $  Bold denotes the best results, and underlined denotes the second-best results.</div>

Slot was tested for effectiveness using both batch and entity-level logs. Table 4 shows that Slot accurately detected APT attacks across various scenarios. From these results, we make the following observations:
• Obs.1: Comparison in Batch Logs. For batch audit log detection, we used the datasets provided by Streamspot and Unicorn as baselines and compared the results with node-level detection methods, including Threatrace. In the relatively simple Streamspot logs, where attack patterns are straightforward and behavioral differences are
9
clear, all detection methods performed well. However, SLOT achieved near-perfect detection results. On the Unicorn dataset, where highly camouflaged attacks significantly reduced the detection efficacy of other methods, SLOT excelled by distinguishing node similarities and strengthening relationship selection. This effectively magnified the differences between benign and malicious behaviors, resulting in superior detection efficacy.
• Obs.2: Comparison in Entity-Level Logs. In entity-level log detection, we compared SLOT with other node-level methods. Log2vec treats logs as nodes rather than entities, fragmenting entity information and weakening aggregation. GNN-based methods like MAGIC, Threatrace, and FLASH also failed to address benign behaviors camouflaging malicious entities, making them vulnerable to evasion. In contrast, SLOT used reinforcement learning to filter out benign-camouflaged neighbors, resulting in superior detection efficacy compared to the SOTA node-level system, FLASH.
### 5.3 System Overhead (RQ2)
<div style="text-align: center;"><img src="https://pplines-online.bj.bcebos.com/deploy/official/paddleocr/pp-ocr-vl//16d757a5-1bbb-46f6-b3f2-e2dc3a53cf16/markdown_9/imgs/img_in_chart_box_118_698_317_886.jpg?authorization=bce-auth-v1%2F5cfe9a5e1454405eb2a975c43eace6ec%2F2025-11-04T09%3A16%3A49Z%2F-1%2F%2Fabd5daca59b4e0d7c7a467be90718d6fc70c4e7b1a33cada4be026afd1fd38c9" alt="Image" width="16%" /></div>

<div style="text-align: center;">(a) Detection rates with changes (b) RAM and CPU overheads with changes in batch size.</div>

<div style="text-align: center;"><img src="https://pplines-online.bj.bcebos.com/deploy/official/paddleocr/pp-ocr-vl//16d757a5-1bbb-46f6-b3f2-e2dc3a53cf16/markdown_9/imgs/img_in_chart_box_339_698_575_886.jpg?authorization=bce-auth-v1%2F5cfe9a5e1454405eb2a975c43eace6ec%2F2025-11-04T09%3A16%3A49Z%2F-1%2F%2Fcbd4dcf3c47eb74217b6701df9d1f94e939d21c95b34d0bcdb32b248870c3aec" alt="Image" width="19%" /></div>

<div style="text-align: center;"><img src="https://pplines-online.bj.bcebos.com/deploy/official/paddleocr/pp-ocr-vl//16d757a5-1bbb-46f6-b3f2-e2dc3a53cf16/markdown_9/imgs/img_in_chart_box_239_950_455_1157.jpg?authorization=bce-auth-v1%2F5cfe9a5e1454405eb2a975c43eace6ec%2F2025-11-04T09%3A16%3A49Z%2F-1%2F%2F43cb955bcaa29d53e741dd4628e221580fca1b28bd9e4a485860b8327ad95372" alt="Image" width="17%" /></div>

<div style="text-align: center;">(c) Detection time consumption compared to MAGIC.</div>

<div style="text-align: center;">Figure 7. Detection efficacy and efficiency of Slot across various batch sizes.</div>

Slot is a detection scheme based on GNN, and therefore, the efficiency overhead during the detection phase depends on the size of the constructed graph, which is determined by the batch size parameter. We comprehensively analyzed the changes in efficiency, CPU and memory overhead of Slot by adjusting the batch size. And compared the time overhead when selecting a batch size of 5000.
Figure 7(a) shows the impact of batch size on detection effectiveness. Since larger graph batches facilitate learning a more complete local structure in GNN processing, the detection efficiency improves as the batch size increases. However, beyond a certain threshold (The maximum number of entities required to complete most of the system activities), the detection capability stabilizes. Considering that batch size has a significant impact on detection accuracy, we analyzed the CPU and memory overhead under different batch sizes. As shown in Figure 7(b), larger batch sizes provide more complex graph structures and node information, which requires more memory and node computation during the graph information propagation process. In terms of detection time, Figure 7(c) shows that SLOT has a faster detection speed compared to MAGIC  $ [17] $ . Although Magic accelerates the efficacy of GNN detection using masking techniques, its KNN distance calculations for anomaly detection still consume a considerable amount of time.
### 5.4 Module Ablation Study (RQ3)
<div style="text-align: center;"><img src="https://pplines-online.bj.bcebos.com/deploy/official/paddleocr/pp-ocr-vl//16d757a5-1bbb-46f6-b3f2-e2dc3a53cf16/markdown_9/imgs/img_in_chart_box_640_702_1109_875.jpg?authorization=bce-auth-v1%2F5cfe9a5e1454405eb2a975c43eace6ec%2F2025-11-04T09%3A16%3A49Z%2F-1%2F%2Ff17aff4e4cd34d7fb775e801ed6850c309fbf896c8c6ec7abc1e7bb564855f62" alt="Image" width="38%" /></div>

<div style="text-align: center;">Figure 8. The impact on accuracy and F1 score from separately ablating features, components, and relations, evaluated on the Unicorn and CADETS datasets.</div>

In our ablation experiments, we re-evaluate the efficacy of SLOT by varying the content of various components to show their impact on the effectiveness of the system. The results are reported in Figure 8.
Effect of semantic features and topological features. In the similarity-aware module, we conducted ablation studies on semantic and topological structures to explore the value of node semantic information and node topology in the selection of node neighbors. Experimental results show that both have a certain impact on node neighbor aggregation. During feature embedding, integrating semantic features and structural features simultaneously can effectively distinguish between benign and malicious nodes. This approach significantly improves the accuracy of similarity segmentation.
Effect of similarity awareness & GNN. Slot characterizes node features through similarity awareness and GNN. We conducted ablation tests on the main modules of Slot.
10
and experiments revealed that using similarity awareness alone cannot deeply explore graph structure information, while GNN without the guidance of neighbor selection is susceptible to the influence of noisy neighbors, misleading node embeddings. Experimental results demonstrate that GNN guided by similarity significantly enhances detection efficacy.
Effect of provenance relation. Current APT detection  $ [37, 45, 49] $  based on GNN often treat provenance graphs as homogeneous, failing to differentiate the heterogeneity of node neighbors, with all relationships being merged into the central node. As illustrated in Figure 8, we compared the detection efficacy of three methods: homogeneous aggregation, multi-relation aggregation, and deep relational aggregation based on hidden relation mining. The experimental results indicate that neighbor relationship filtering based on reinforced selection effectively reduces the induced expression of benign neighbors on malicious nodes. Additionally, by incorporating hidden relational information, the model can mine deeper feature information, thereby accelerating the effective propagation of information flow and enhancing detection efficiency.
### 5.5 Hyperparameter Investigation (RQ4)
<div style="text-align: center;"><img src="https://pplines-online.bj.bcebos.com/deploy/official/paddleocr/pp-ocr-vl//16d757a5-1bbb-46f6-b3f2-e2dc3a53cf16/markdown_10/imgs/img_in_chart_box_109_761_325_909.jpg?authorization=bce-auth-v1%2F5cfe9a5e1454405eb2a975c43eace6ec%2F2025-11-04T09%3A16%3A50Z%2F-1%2F%2Ff8b203decb805f9ecbce36f996c628939f1e8fc01434ed9572ebeccbab01430a" alt="Image" width="17%" /></div>

<div style="text-align: center;"><img src="https://pplines-online.bj.bcebos.com/deploy/official/paddleocr/pp-ocr-vl//16d757a5-1bbb-46f6-b3f2-e2dc3a53cf16/markdown_10/imgs/img_in_chart_box_105_918_329_1074.jpg?authorization=bce-auth-v1%2F5cfe9a5e1454405eb2a975c43eace6ec%2F2025-11-04T09%3A16%3A50Z%2F-1%2F%2Fcdf110149fd9c6d682f36fc08b5982c41a8a10de8fdd325224aee57d2ce05347" alt="Image" width="18%" /></div>

<div style="text-align: center;"><img src="https://pplines-online.bj.bcebos.com/deploy/official/paddleocr/pp-ocr-vl//16d757a5-1bbb-46f6-b3f2-e2dc3a53cf16/markdown_10/imgs/img_in_chart_box_339_756_563_909.jpg?authorization=bce-auth-v1%2F5cfe9a5e1454405eb2a975c43eace6ec%2F2025-11-04T09%3A16%3A50Z%2F-1%2F%2F724c9e07fc4f3d67b985c50f5b3059053f0a27824b7bc30b98bf1e0d2d3813bd" alt="Image" width="18%" /></div>

<div style="text-align: center;"><img src="https://pplines-online.bj.bcebos.com/deploy/official/paddleocr/pp-ocr-vl//16d757a5-1bbb-46f6-b3f2-e2dc3a53cf16/markdown_10/imgs/img_in_chart_box_344_919_569_1073.jpg?authorization=bce-auth-v1%2F5cfe9a5e1454405eb2a975c43eace6ec%2F2025-11-04T09%3A16%3A50Z%2F-1%2F%2F03669b5431abcb3369b0fd8e0e7021112a147ae3d8607c791ab15f6351c71f0d" alt="Image" width="18%" /></div>

<div style="text-align: center;">Figure 9. Detection efficacy (i.e., accuracy, precision, recall, F1) with different hyperparameters on the CADETS dataset.</div>

Previously, we employed a fixed set of optimal parameters; in this section, we discuss the impact of several critical hyperparameters on the threat detection efficacy of Slor. We examined the logic behind the choice of hyperparameters separately on CADETS shown in Figure 9. When testing one of these parameters, we maintained the others consistent with the baseline. We summarize the results with the following observations:
• Embedding Size d: In the embedding process, node features are embedded and mapped to low-dimensional vectors while preserving as much of their original feature attributes as possible. As shown in Figure 9, as the embedding dimension increases, the detection metrics improve significantly, indicating that a larger embedding dimension effectively captures more information. However, an excessively large dimension can lead to feature sparsity, which severely impacts detection efficacy and results in higher memory consumption. When the dimension is set to 32, the model achieves the fastest convergence and reaches high efficacy metrics.
• Number of Layers l: Generally, increasing the number of layers in a model can capture deeper information. However, as shown in Figure 9, there is no significant improvement in efficacy with an increase in the number of layers. Particularly, when the model exceeds three layers, there is a clear occurrence of overfitting. Therefore, choosing a single-layer model can achieve the best balance between detection efficacy and efficiency cost.
• Similarity Loss Weight  $ \lambda_{1} $ : Figure 8 demonstrates the significant impact of similarity calculations on SLOT. Figure 9 shows the effect of different similarity loss weights on detection efficacy. It is evident that when the weight of the similarity loss is twice that of the GNN loss, there is a balanced integration of feature similarity perception and GNN information aggregation, resulting in optimal efficacy.
• Reinforcement Learning step  $ \tau $ : In reinforcement learning, selecting the appropriate action step size allows all thresholds to be updated and converge over multiple epochs. When the thresholds oscillate for several rounds, reaching Formula 9 is the termination condition. Experiments have demonstrated that SLOT achieve optimal efficacy when the step size is set to 0.01.
### 5.6 Resilience to Adversarial Attacks (RQ5)
Adversarial Attack: Mimicry attacks against provenance-based APT detection are carried out by altering the original data to incorporate more benign features, thereby 'mimicking benign behavior' in order to evade detection. To evaluate the resilience of the SLOT system against adversarial attacks, we employed the attack methods described in [10] and [37], which involve inserting benign structures into the attack graph. This allowed us to assess the robustness of SLOT.
For evaluation purposes, we used the CADETS dataset as the example because of its relatively small scale. As shown in Figure 10, both SLOT and FLASH exhibit a certain level of robustness against imitation attacks when only a small number of benign events are introduced. However, as more benign events are incorporated, we observe a significant decline in FLASH's detection efficacy, while SLOT remains unaffected by the imitation attack, demonstrating greater robustness compared to the baseline. We attribute this to the fact that FLASH, along with other embedding-based APT detections, does not thoroughly account for the heterogeneous relationships between nodes during propagation and
11
<div style="text-align: center;"><img src="https://pplines-online.bj.bcebos.com/deploy/official/paddleocr/pp-ocr-vl//16d757a5-1bbb-46f6-b3f2-e2dc3a53cf16/markdown_11/imgs/img_in_chart_box_117_151_581_376.jpg?authorization=bce-auth-v1%2F5cfe9a5e1454405eb2a975c43eace6ec%2F2025-11-04T09%3A16%3A51Z%2F-1%2F%2F515851c990d30588b2f42ef614e8eb6c941d1380ddac63bb0e71d74481ec095c" alt="Image" width="37%" /></div>

<div style="text-align: center;">Figure 10. Resilience against adversarial attacks.</div>

aggregation. In contrast, SLOT effectively guides neighbor selection by distinguishing behavioral similarity. Through the use of multi-armed bandit-based reinforcement learning, SLOT dynamically filters out benign camouflage connected to malicious nodes, thereby exhibiting strong resistance to imitation attacks.
### 5.7 Alert Validation (RQ6)
<div style="text-align: center;"><img src="https://pplines-online.bj.bcebos.com/deploy/official/paddleocr/pp-ocr-vl//16d757a5-1bbb-46f6-b3f2-e2dc3a53cf16/markdown_11/imgs/img_in_chart_box_133_698_563_871.jpg?authorization=bce-auth-v1%2F5cfe9a5e1454405eb2a975c43eace6ec%2F2025-11-04T09%3A16%3A51Z%2F-1%2F%2F9653b591e9142dca8ad8978eeb0a5352ed56231a518d272046fa84c681138d34" alt="Image" width="35%" /></div>

<div style="text-align: center;">Figure 11. The number of alerts produced with the DARPA E3 dataset and the false positive rate within the generated attack chain.</div>

The ultimate goal of SLOT is to provide security analysts with more effective and concise attack insights, thereby accelerating the alert-handling process. We believe that APT detection should achieve the following when reconstructing attack chains: (1) Provide concise and readable attack chains, (2) Include as few false positive nodes in the attack chain as possible.
<div style="text-align: center;"><img src="https://pplines-online.bj.bcebos.com/deploy/official/paddleocr/pp-ocr-vl//16d757a5-1bbb-46f6-b3f2-e2dc3a53cf16/markdown_11/imgs/img_in_image_box_144_1183_548_1334.jpg?authorization=bce-auth-v1%2F5cfe9a5e1454405eb2a975c43eace6ec%2F2025-11-04T09%3A16%3A51Z%2F-1%2F%2Fe51bf80679b573ceed0d620cb94d7fe6098ae9115a7d0edf37d7cbd55493ab34" alt="Image" width="33%" /></div>

<div style="text-align: center;">Figure 12. An example of benign activities reconstructed within the alert nodes.</div>

<div style="text-align: center;"><img src="https://pplines-online.bj.bcebos.com/deploy/official/paddleocr/pp-ocr-vl//16d757a5-1bbb-46f6-b3f2-e2dc3a53cf16/markdown_11/imgs/img_in_image_box_673_142_1077_292.jpg?authorization=bce-auth-v1%2F5cfe9a5e1454405eb2a975c43eace6ec%2F2025-11-04T09%3A16%3A51Z%2F-1%2F%2F070deb870faf2162142ed63956978cdbad688d8457023671ff3feee1afcfea64" alt="Image" width="33%" /></div>

<div style="text-align: center;">Figure 13. An example of attack activities reconstructed within the alert nodes.</div>

As shown in Figure 11, SLOT can rapidly filter and identify the most relevant paths during the complex attack chain decision-making process, using TTP to exclude paths that may appear related but are commonly found in normal operations. This further enhances the filtering of false positives in attack-chains. Additionally, as described by FLASH $ ^{[37]} $ , the reconstructed attack graph exhibits strong event representation capabilities, eliminating the need for security analysts to trace through numerous anomalous nodes. As shown in Figure 12, the benign structure in CADETS, which is a series of activities generated by "wget", is highly aggregated. This effectively accelerates the filtering and selection of benign entity graphs. As shown in Figure 13, the attack scanning behavior in THEIA initiated by the malicious process "/var/log/email" involves more than 6000 scanned network entities. The aggregation of the attack chain significantly reduces the time required for analysts to manually trace these activities. The use of attack chains significantly reduces the number of items that analysts need to review, as the number of attack chains is substantially smaller than that of anomalous nodes.
Case Study. Using the attack scenario from Section 3.1, we demonstrate how SLOT detects APT attacks from audit logs and reconstructs the attack chain. In this scenario, the attacker leverages a Firefox backdoor and embeds benign DNS resolutions to mask their activities. SLOT employs semantic and topological embeddings to derive primary node representations and calculate similarities, effectively distinguishing between benign user behaviors (e.g., Firefox accessing common IPs) and malicious activities. By segmenting similarities between Firefox1 and Firefox2, and employing reinforcement learning, SLOT filters out benign activities disguised within attack events. Using GNN, it learns the genuine behavioral patterns of nodes. In the final Attack-chain Reconstruction phase, TTP encoding further separates benign peripheral nodes, resulting in the red-highlighted attack chain in the diagram. The core malicious activities include communication with IP 146.153.68.151, downloading and executing a malicious file (/home/admin/profile), and interacting with IP 149.52.198.23 to manipulate processes for attack scanning.
12
## 6 Conclusion
The persistent and evolving threat posed by advanced persistent threats (APTs) necessitates innovative detection solutions that can effectively navigate the complexities of modern cyberattacks. Existing methods often fall short in addressing the full spectrum of challenges associated with APT detection, such as limited detection efficacy, vulnerability to adversarial attacks, and insufficient support in developing defense strategies. To bridge these gaps, we introduced SLOT, an effective APT detection approach that leverages provenance graphs and graph reinforcement learning. With advanced provenance graph digging techniques, SLOT excels in uncovering multi-level hidden relationships among system behaviors. Besides, SLOT leverages graph reinforcement learning to dynamically adapt to new user activities and attack strategies, significantly enhancing its accuracy and resilience in highly adversarial environments. By automatically constructing attack chains, SLOT not only identifies attack paths with precision but also supports the development of effective defense strategies. Our evaluations reveal SLOT's effectiveness, achieving approximately 99% APT detection accuracy and outperforming state-of-the-art approaches. Further experiments also highlight SLOT's high efficiency, resilience to adversarial attacks, and ability to support the development of defense strategies.
13
## References
[1] [n.d.]. Darpa transparent computing program engagement 3 data release. https://github.com/darpa-i2o/Transparent-Computing. 2020.
[2] [n.d.]. MITRE ATT&CK Framework. https://attack.mitre.org/
[3] [n.d.]. The streamspot dataset. https://github.com/sbustreamspot/sbustreamspot-data. 2016.
[4] Abdulellah Alsaheel, Yuhong Nan, Shiqing Ma, Le Yu, Gregory Walkup, Z Berkay Celik, Xiangyu Zhang, and Dongyan Xu. 2021. {ATLAS}: A sequence-based learning approach for attack investigation. In 30th USENIX security symposium (USENIX security 21). 3005–3022.
[5] Adel Alshamrani, Sowmya Myneni, Ankur Chowdhary, and Dijiang Huang. 2019. A survey on advanced persistent threats: Techniques, solutions, challenges, and research opportunities. IEEE Communications Surveys & Tutorials 21, 2 (2019), 1851–1877.
[6] Davide Bacciu and Danilo Numeroso. 2022. Explaining deep graph networks via input perturbation. IEEE Transactions on Neural Networks and Learning Systems 34, 12 (2022), 10334–10345.
[7] Miaojiang Chen, Wei Liu, Tian Wang, Shaobo Zhang, and Anfeng Liu. 2022. A game-based deep reinforcement learning approach for energy-efficient computation in MEC systems. Knowledge-Based Systems 235 (2022), 107660.
[8] Zijun Cheng, Qiujian Lv, Jinyuan Liang, Yan Wang, Degang Sun, Thomas Pasquier, and Xueyuan Han. 2023. Kairos:: Practical Intrusion Detection and Investigation using Whole-system Provenance. arXiv preprint arXiv:2308.05034 (2023).
[9] Zhangyu Cheng, Chengming Zou, and Jianwei Dong. 2019. Outlier detection using isolation forest and local outlier factor. In Proceedings of the conference on research in adaptive and convergent systems. 161–168.
[10] Akul Goyal, Xueyuan Han, Gang Wang, and Adam Bates. 2023. Sometimes, you aren’t what you do: Mimicry attacks against provenance graph host intrusion detection systems. In 30th Network and Distributed System Security Symposium.
[11] Will Hamilton, Zhitao Ying, and Jure Leskovec. 2017. Inductive representation learning on large graphs. Advances in neural information processing systems 30 (2017).
[12] Xueyuan Han, Thomas Pasquier, Adam Bates, James Mickens, and Margo Seltzer. 2020. Unicorn: Runtime provenance-based detector for advanced persistent threats. arXiv preprint arXiv:2001.01525 (2020).
[13] Wajih Ul Hassan, Adam Bates, and Daniel Marino. 2020. Tactical provenance analysis for endpoint detection and response systems. In 2020 IEEE Symposium on Security and Privacy (SP). IEEE, 1172–1189.
[14] Wajih Ul Hassan, Shengjian Guo, Ding Li, Zhengzhang Chen, Kangkook Jee, Zhichun Li, and Adam Bates. 2019. Nodoze: Combatting threat alert fatigue with automated provenance triage. In network and distributed systems security symposium.
[15] Md Nahid Hossain, Sadegh M Milajerdi, Junao Wang, Birhanu Eshete, Rigel Gjomemo, R Sekar, Scott Stoller, and VN Venkatakrishnan. 2017. SLEUTH: Real-time attack scenario reconstruction from COTS audit data. In 26th USENIX Security Symposium (USENIX Security 17). 487–504.
[16] Md Nahid Hossain, Sanaz Sheikhi, and R Sekar. 2020. Combating dependence explosion in forensic analysis using alternative tag propagation semantics. In 2020 IEEE Symposium on Security and Privacy (SP). IEEE, 1139–1155.
[17] Zian Jia, Yun Xiong, Yuhong Nan, Yao Zhang, Jinjing Zhao, and Mi Wen. 2023. MAGIC: Detecting Advanced Persistent Threats via Masked Graph Representation Learning. arXiv preprint arXiv:2310.09831 (2023).
[18] Chao Jiang, Yi He, Richard Chapman, and Hongyi Wu. 2022. Camouflaged poisoning attack on graph neural networks. In Proceedings of the 2022 International Conference on Multimedia Retrieval. 451–461.
[19] Jiechuan Jiang, Chen Dun, Tiejun Huang, and Zongqing Lu. 2018. Graph convolutional reinforcement learning. arXiv preprint arXiv:1810.09202 (2018).
[20] Maya Kapoor, Joshua Melton, Michael Ridenhour, Siddharth Krishnan, and Thomas Moyer. 2021. PROV-GEM: automated provenance analysis framework using graph embeddings. In 2021 20th IEEE International Conference on Machine Learning and Applications (ICMLA). IEEE, 1720–1727.
[21] Sergey Levine, Peter Pastor, Alex Krizhevsky, Julian Ibarz, and Deirdre Quillen. 2018. Learning hand-eye coordination for robotic grasping with deep learning and large-scale data collection. The International journal of robotics research 37, 4-5 (2018), 421-436.
[22] Derek Lim, Felix Hohne, Xiuyu Li, Sijia Linda Huang, Vaishnavi Gupta, Omkar Bhalerao, and Ser Nam Lim. 2021. Large scale learning on non-homophilous graphs: New benchmarks and strong simple methods. Advances in Neural Information Processing Systems 34 (2021), 20887–20902.
[23] Yankai Lin, Zhiyuan Liu, Maosong Sun, Yang Liu, and Xuan Zhu. 2015. Learning entity and relation embeddings for knowledge graph completion. In Proceedings of the AAAI conference on artificial intelligence, Vol. 29.
[24] Fucheng Liu, Yu Wen, Dongxue Zhang, Xihe Jiang, Xinyu Xing, and Dan Meng. 2019. Log2vec: A heterogeneous graph embedding based approach for detecting cyber threats within enterprise. In Proceedings of the 2019 ACM SIGSAC conference on computer and communications security. 1777–1794.
[25] Yushan Liu, Mu Zhang, Ding Li, Kangkook Jee, Zhichun Li, Zhenyu Wu, Junghwan Rhee, and Prateek Mittal. 2018. Towards a Timely Causality Analysis for Enterprise Security. In NDSS.
[26] Emaad Manzoor, Sadegh M Milajerdi, and Leman Akoglu. 2016. Fast memory-efficient anomaly detection in streaming heterogeneous graphs. In Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining. 1035–1044.
[27] Tomas Mikolov. 2013. Efficient estimation of word representations in vector space. arXiv preprint arXiv:1301.3781 (2013).
[28] Sadegh M Milajerdi, Birhanu Eshete, Rigel Gjomemo, and VN Venkatakrishnan. 2019. Poirot: Aligning attack behavior with kernel audit records for cyber threat hunting. In Proceedings of the 2019 ACM SIGSAC conference on computer and communications security. 1795–1812.
[29] Sadegh M Milajerdi, Rigel Gjomemo, Birhanu Eshete, Ramachandran Sekar, and VN Venkatakrishnan. 2019. Holmes: real-time apt detection through correlation of suspicious information flows. In 2019 IEEE Symposium on Security and Privacy (SP). IEEE, 1137–1152.
[30] Dorcas Ofori-Boateng, I Segovia Dominguez, C Akcora, Murat Kantarcioglu, and Yulia R Gel. 2021. Topological anomaly detection in dynamic multilayer blockchain networks. In Machine Learning and Knowledge Discovery in Databases. Research Track: European Conference, ECML PKDD 2021, Bilbao, Spain, September 13–17, 2021, Proceedings, Part I 21. Springer, 788–804.
[31] Riccardo Paccagnella, Pubali Datta, Wajih Ul Hassan, Adam Bates, Christopher Fletcher, Andrew Miller, and Dave Tian. 2020. Custos: Practical tamper-evident auditing of operating systems using trusted execution. In Network and distributed system security symposium.
[32] Thomas Pasquier, Xueyuan Han, Mark Goldstein, Thomas Moyer, David Eyers, Margo Seltzer, and Jean Bacon. 2017. Practical whole-system provenance capture. In Proceedings of the 2017 Symposium on Cloud Computing. 405–418.
[33] Thomas Pasquier, Xueyuan Han, Thomas Moyer, Adam Bates, Olivier Hermant, David Eyers, Jean Bacon, and Margo Seltzer. 2018. Runtime analysis of whole-system provenance. In Proceedings of the 2018 ACM SIGSAC conference on computer and communications security. 1601–1616.
[34] Kexin Pei, Zhongshu Gu, Brendan Saltaformaggio, Shiqing Ma, Fei Wang, Zhiwei Zhang, Luo Si, Xiangyu Zhang, and Dongyan Xu. 2016. Hercule: Attack story reconstruction via community discovery on correlated log graph. In Proceedings of the 32Nd Annual Conference on Computer Security Applications. 583–595.
14
[35] Hao Peng, Ruitong Zhang, Yingtong Dou, Renyu Yang, Jingyi Zhang, and Philip S Yu. 2021. Reinforced neighborhood selection guided multirelational graph neural networks. ACM Transactions on Information Systems (TOIS) 40, 4 (2021), 1–46.
[36] Marius-Constantin Popescu, Valentina E Balas, Liliana Perescu-Popescu, and Nikos Mastorakis. 2009. Multilayer perceptron and neural networks. WSEAS Transactions on Circuits and Systems 8, 7 (2009), 579–588.
[37] Mati Ur Rehman, Hadi Ahmadi, and Wajih Ul Hassan. 2024. FLASH: A Comprehensive Approach to Intrusion Detection via Provenance Graph Representation Learning. In 2024 IEEE Symposium on Security and Privacy (SP). IEEE Computer Society, 139–139.
[38] SektorCERT. 2023. The attack against Danish critical infrastructure. Available online. https://sektorcert.dk/wp-content/uploads/2023/11/SektorCERT-The-attack-against-Danish-critical-infrastructure-TLP-CLEAR.pdf
[39] Amit Sharma, Brij B Gupta, Awadhesh Kumar Singh, and VK Saraswat. 2023. Advanced persistent threats (apt): evolution, anatomy, attribution and countermeasures. Journal of Ambient Intelligence and Humanized Computing 14, 7 (2023), 9355–9381.
[40] Qingyun Sun, Jianxin Li, Hao Peng, Jia Wu, Yuanxing Ning, Philip S Yu, and Lifang He. 2021. Sugar: Subgraph neural network with reinforcement pooling and self-supervised mutual information mechanism. In Proceedings of the web conference 2021. 2081–2091.
[41] Threat Hunter Team. 2023. Grayling: Previously Unseen Threat Actor Targets Multiple Organizations in Taiwan. https://symantec-enterprise-blogs.security.com/threat-intelligence/grayling-taiwan-cyber-attacks
[42] Victor Uc-Cetina, Nicolás Navarro-Guerrero, Anabel Martin-Gonzalez, Cornelius Weber, and Stefan Wermter. 2023. Survey on reinforcement learning for language processing. Artificial Intelligence Review 56, 2 (2023), 1543–1575.
[43] Petar Veličković, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua Bengio. 2017. Graph attention networks. arXiv preprint arXiv:1710.10903 (2017).
[44] Qi Wang, Wajih Ul Hassan, Ding Li, Kangkook Jee, Xiao Yu, Kexuan Zou, Junghwan Rhee, Zhengzhang Chen, Wei Cheng, Carl A Gunter, et al. 2020. You Are What You Do: Hunting Stealthy Malware via Data Provenance Analysis. In NDSS.
[45] Su Wang, Zhiliang Wang, Tao Zhou, Hongbin Sun, Xia Yin, Dongqi Han, Han Zhang, Xingang Shi, and Jiahai Yang. 2022. Threatrace: Detecting and tracing host-based threats in node level through provenance graph learning. IEEE Transactions on Information Forensics and Security 17 (2022), 3972–3987.
[46] Rui Wen, Jianyu Wang, Chunming Wu, and Jian Xiong. 2020. Asa: Adversary situation awareness via heterogeneous graph convolutional networks. In Companion Proceedings of the Web Conference 2020. 674–678.
[47] Zhiwen Xie, Runjie Zhu, Jin Liu, Guangyou Zhou, and Jimmy Xiangji Huang. 2022. An efficiency relation-specific graph transformation network for knowledge graph representation learning. Information Processing & Management 59, 6 (2022), 103076.
[48] Hao Yuan, Haiyang Yu, Jie Wang, Kang Li, and Shuiwang Ji. 2021. On explainability of graph neural networks via subgraph explorations. In International conference on machine learning. PMLR, 12241–12252.
[49] Jun Zengy, Xiang Wang, Jiahao Liu, Yinfang Chen, Zhenkai Liang, Tat-Seng Chua, and Zheng Leong Chua. 2022. Shadowatcher: Recommendation-guided cyber threat analysis using system audit records. In 2022 IEEE Symposium on Security and Privacy (SP). IEEE, 489–506.
[50] Zaixi Zhang, Qi Liu, Qingyong Hu, and Chee-Kong Lee. 2022. Hierarchical graph transformer with adaptive node sampling. Advances in Neural Information Processing Systems 35 (2022), 21171–21183.
[51] Elena Zheleva and Lise Getoor. 2009. To join or not to join: the illusion of privacy in social networks with mixed public and private user profiles. In Proceedings of the 18th international conference on World wide web. 531–540.
[52] Jiong Zhu, Yujun Yan, Lingxiao Zhao, Mark Heimann, Leman Akoglu, and Danai Koutra. 2020. Beyond homophily in graph neural networks: Current limitations and effective designs. Advances in neural information processing systems 33 (2020), 7793–7804.
15
